{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vietnamese-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from gpflow import set_trainable\n",
    "from gpflow.utilities import ops, print_summary\n",
    "from gpflow.ci_utils import ci_niter\n",
    "from gpflow.config import set_default_float, default_float, set_default_summary_fmt\n",
    "\n",
    "f64 = gpflow.utilities.to_default_float\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aggressive-analyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  54 of 54 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "stocks=\"ESS,GRMN,SCHW,SPG,CF,ACN,LB,ADP,TROW,CTSH,FIS,COP,INTC,NFX,BF-B,TDG,MCHP,D,SYY,MTD,FITB,COL,PVH,JBHT,DAL,UNH,AON,CRM,SLB,XEC,XRAY,GPN,ALGN,LNC,ADM,KSU,YUM,AEP,GPS,LOW,DLR,ADS,ADSK,STT,AME,CAG,HRL,ESRX,XOM,NSC,A,PH,AMD,BBY\"\n",
    "stocks=stocks.replace(\",\", \" \")\n",
    "yf_stocks = yf.download(stocks, start=\"2005-01-01\", end=\"2021-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "passing-prayer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4028"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_rets = yf_stocks['Adj Close'].pct_change()\n",
    "len(daily_rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secret-correlation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4027"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_rets = daily_rets[:][1:]\n",
    "len(daily_rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "major-blair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r = daily_rets[:][:]\n",
    "df_r = pd.DataFrame(test_r)\n",
    "df_t = df_r.T\n",
    "df = df_t.dropna()\n",
    "df_train = df.iloc[:50, :10]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wrong-operator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Stocks in Portfolio: 50 and Number of Days: 10\n"
     ]
    }
   ],
   "source": [
    "r = tf.convert_to_tensor(df_train, dtype=default_float())\n",
    "print(\"Number of Stocks in Portfolio: {} and Number of Days: {}\".format(r.shape[0], r.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aggressive-manchester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 4  # number of latent dimensions\n",
    "num_inducing = 50  # number of inducing pts\n",
    "num_data = r.shape[0]\n",
    "print(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "harmful-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_init = ops.pca_reduce(r, latent_dim)\n",
    "X_var_init = tf.ones((num_data, latent_dim), dtype=default_float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civil-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)  # for reproducibility\n",
    "inducing_variable = tf.convert_to_tensor(\n",
    "    np.random.permutation(X_mean_init.numpy())[:num_inducing], dtype=default_float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "modular-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-output kernel from kernel list\n",
    "lengthscales = tf.convert_to_tensor([1.0] * latent_dim, dtype=default_float())\n",
    "kernel = gpflow.kernels.RBF(lengthscales=lengthscales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "major-aspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════════════════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═══════════════════════════════════════════════════════╕\n",
      "│ name                                         │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │ value                                                 │\n",
      "╞══════════════════════════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═══════════════════════════════════════════════════════╡\n",
      "│ BayesianGPLVM.kernel.kernels[0].variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 1.0                                                   │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.kernel.kernels[0].lengthscales │ Parameter │ Softplus         │         │ True        │ (4,)    │ float64 │ [1., 1., 1....                                        │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.kernel.kernels[1].variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 1.0                                                   │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.likelihood.variance            │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 1.0                                                   │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.X_data_mean                    │ Parameter │ Identity         │         │ True        │ (50, 4) │ float64 │ [[2.98051905e-02, 2.96205642e-03, 1.32408028e-02...   │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.X_data_var                     │ Parameter │ Softplus         │         │ True        │ (50, 4) │ float64 │ [[1., 1., 1....                                       │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.inducing_variable.Z            │ Parameter │ Identity         │         │ True        │ (50, 4) │ float64 │ [[7.58224490e-03, -1.65186976e-02, -1.50523967e-02... │\n",
      "╘══════════════════════════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═══════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "gplvm = gpflow.models.BayesianGPLVM(\n",
    "    r,\n",
    "    X_data_mean=X_mean_init,\n",
    "    X_data_var=X_var_init,\n",
    "    kernel=kernel,\n",
    "    inducing_variable=inducing_variable,\n",
    ")\n",
    "print_summary(gplvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "seasonal-munich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════════════════════════════════════╤═══════════╤══════════════════╤══════════════╤═════════════╤═════════╤═════════╤═══════════════════════════════════════════════════════╕\n",
      "│ name                                         │ class     │ transform        │ prior        │ trainable   │ shape   │ dtype   │ value                                                 │\n",
      "╞══════════════════════════════════════════════╪═══════════╪══════════════════╪══════════════╪═════════════╪═════════╪═════════╪═══════════════════════════════════════════════════════╡\n",
      "│ BayesianGPLVM.kernel.kernels[0].variance     │ Parameter │ Softplus         │ InverseGamma │ True        │ ()      │ float64 │ 1.0                                                   │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼──────────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.kernel.kernels[0].lengthscales │ Parameter │ Softplus         │ InverseGamma │ True        │ (4,)    │ float64 │ [1., 1., 1....                                        │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼──────────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.kernel.kernels[1].variance     │ Parameter │ Softplus         │ Normal       │ True        │ ()      │ float64 │ 1.0                                                   │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼──────────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.likelihood.variance            │ Parameter │ Softplus + Shift │              │ True        │ ()      │ float64 │ 0.009999999999999998                                  │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼──────────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.X_data_mean                    │ Parameter │ Identity         │              │ True        │ (50, 4) │ float64 │ [[2.98051905e-02, 2.96205642e-03, 1.32408028e-02...   │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼──────────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.X_data_var                     │ Parameter │ Softplus         │              │ True        │ (50, 4) │ float64 │ [[1., 1., 1....                                       │\n",
      "├──────────────────────────────────────────────┼───────────┼──────────────────┼──────────────┼─────────────┼─────────┼─────────┼───────────────────────────────────────────────────────┤\n",
      "│ BayesianGPLVM.inducing_variable.Z            │ Parameter │ Identity         │              │ True        │ (50, 4) │ float64 │ [[7.58224490e-03, -1.65186976e-02, -1.50523967e-02... │\n",
      "╘══════════════════════════════════════════════╧═══════════╧══════════════════╧══════════════╧═════════════╧═════════╧═════════╧═══════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "gplvm.likelihood.variance.assign(0.01)\n",
    "gplvm.kernel.kernels[0].variance.prior = tfd.InverseGamma(f64(3.0),f64(1.0))\n",
    "gplvm.kernel.kernels[0].lengthscales.prior = tfd.InverseGamma(f64(3.0),f64(1.0))\n",
    "gplvm.kernel.kernels[1].variance.prior = tfd.Normal(0,0.5)\n",
    "print_summary(gplvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable(gplvm.inducing_variable, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = gpflow.optimizers.Scipy()\n",
    "maxiter = ci_niter(1000)\n",
    "_ = opt.minimize(\n",
    "    gplvm.training_loss,\n",
    "    variables=gplvm.trainable_variables,\n",
    "    options=dict(maxiter=maxiter),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary(gplvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = ops.pca_reduce(r, latent_dim).numpy()\n",
    "gplvm_X_mean = gplvm.X_data_mean.numpy()\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "ax[0].scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "ax[1].scatter(gplvm_X_mean[:, 0], gplvm_X_mean[:, 1])\n",
    "ax[0].set_title(\"PCA\")\n",
    "ax[1].set_title(\"Bayesian GPLVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable(gplvm.inducing_variable.Z, False)\n",
    "set_trainable(gplvm.likelihood.variance, False)\n",
    "set_trainable(gplvm.X_data_var, False)\n",
    "print_summary(gplvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_burnin_steps = ci_niter(100)\n",
    "num_samples = ci_niter(500)\n",
    "\n",
    "# Note that here we need model.trainable_parameters, not trainable_variables - only parameters can have priors!\n",
    "hmc_helper = gpflow.optimizers.SamplingHelper(\n",
    "    gplvm.log_posterior_density, gplvm.trainable_parameters\n",
    ")\n",
    "\n",
    "hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=hmc_helper.target_log_prob_fn, num_leapfrog_steps=10, step_size=0.01\n",
    ")\n",
    "\n",
    "adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "    hmc, num_adaptation_steps=10, target_accept_prob=f64(0.75), adaptation_rate=0.1\n",
    ")\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def run_chain_fn():\n",
    "    return tfp.mcmc.sample_chain(\n",
    "        num_results=num_samples,\n",
    "        num_burnin_steps=num_burnin_steps,\n",
    "        current_state=hmc_helper.current_state,\n",
    "        kernel=adaptive_hmc,\n",
    "        trace_fn=lambda _, pkr: pkr.inner_results.is_accepted,\n",
    "    )\n",
    "\n",
    "\n",
    "samples, _ = run_chain_fn()\n",
    "constrained_samples = hmc_helper.convert_to_constrained_values(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary(gplvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = ops.pca_reduce(r, latent_dim).numpy()\n",
    "gplvm_X_mean = gplvm.X_data_mean.numpy()\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "ax[0].scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "ax[1].scatter(gplvm_X_mean[:, 0], gplvm_X_mean[:, 1])\n",
    "ax[0].set_title(\"PCA\")\n",
    "ax[1].set_title(\"Bayesian GPLVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_to_name = {param: name for name, param in gpflow.utilities.parameter_dict(gplvm).items()}\n",
    "\n",
    "def marginal_samples(samples, parameters, y_axis_label):\n",
    "    fig, axes = plt.subplots(1, len(param_to_name), figsize=(15, 3), constrained_layout=True)\n",
    "    for ax, val, param in zip(axes, samples, parameters):\n",
    "        ax.hist(np.stack(val).flatten(), bins=20)\n",
    "        ax.set_title(param_to_name[param])\n",
    "    fig.suptitle(y_axis_label)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "marginal_samples(samples, gplvm.trainable_parameters, \"unconstrained variable samples\")\n",
    "marginal_samples(constrained_samples, gplvm.trainable_parameters, \"constrained parameter samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = kernel.K(gplvm.X_data_mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(K)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-trinidad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
